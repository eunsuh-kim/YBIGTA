{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN_pVd5cU2QQ"
   },
   "source": [
    "# 과제: MNIST 데이터를 나만의 NN model로 95 % 이상의 성능으로 training 시켜보자!\n",
    "\n",
    "\n",
    "## Loading MNIST training data\n",
    "\n",
    "출처: 19기 DS 정은서님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjzqUeS3gHIx"
   },
   "source": [
    "MNIST data: 손글씨 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hwZNV5MFU2QQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Loading the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scaling(image data는 min-max scaling 주로 사용)\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDU8J2xRU2QQ"
   },
   "source": [
    "## Training Data\n",
    "28 * 28 pixel 값을 가진 총 60000개의 이미지 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jVvXmjQSU2QQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VTAAYKSU2QQ"
   },
   "source": [
    "Neural network 모델에 맞게 이미지 데이터를 벡터 형태로 데이터를 reshape 합니다.  \n",
    "(Model을 만들 때 *keras.layers.Flatten(input_shape=(28, 28)) 이용해도 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dq36yUX8U2QR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test = x_train.reshape((-1, 28*28)), x_test.reshape((-1, 28*28))\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zrQLH9iXU2QR"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hint: x_train[0].reshape()\n",
    "plt.imshow(x_train[0].reshape(28, 28)).set_cmap('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YZXzr-AU2QR"
   },
   "source": [
    "## Training Labels\n",
    "이미지 데이터가 나타내는 숫자값을 label로 가지고 있고, 0부터 9까지의 값을 나타냄  \n",
    "마찬가지로, 60000개의 label이 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V-JVvQcJU2QR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PgAkJK6yU2QR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show MNIST label for above data\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaI3Kv_GU2QR"
   },
   "source": [
    "## 나만의 모델을 tensorflow keras API 를 이용해 만들어 봅시다~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSshVnt2U2QS"
   },
   "source": [
    "* parameters for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "coUZ53nKU2QS"
   },
   "outputs": [],
   "source": [
    "activation_list = [\"sigmoid\", \"relu\", \"softmax\", \"tanh\"]\n",
    "\n",
    "loss_list = [\"sparse_categorical_crossentropy\",\n",
    "             \"categorical_crossentropy\", \n",
    "             \"binary_crossentropy\"] #binary는 안 좋음\n",
    "\n",
    "optimizer_list = [\"sgd\", \"adam\", \"rmsprop\", \"adagrad\"]\n",
    "\n",
    "initializer_list = [tf.keras.initializers.RandomNormal(), \n",
    "                    tf.keras.initializers.RandomUniform(), \n",
    "                    tf.keras.initializers.he_normal(), \n",
    "                    tf.keras.initializers.he_uniform(), \n",
    "                    tf.keras.initializers.GlorotUniform(),\n",
    "                    tf.keras.initializers.GlorotNormal()]\n",
    "\n",
    "# dropout\n",
    "dropout_rate = 0.3\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, input_dim=784, activation = \"sigmoid\"),\n",
    "    tf.keras.layers.Dense(2, activation = \"sigmoid\"),\n",
    "    tf.keras.layers.Dropout(dropout_rate)\n",
    "])\n",
    "\n",
    "\n",
    "# regularizer\n",
    "regularizer = tf.keras.regularizers.l1(1e-3)\n",
    "regularizer = tf.keras.regularizers.l2(1e-3)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
    "                          activity_regularizer=regularizer)\n",
    "])\n",
    "\n",
    "# weight initialization\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
    "                          kernel_initializer=initializer_list[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-6ZTz4AU2QS"
   },
   "source": [
    "#### My Own Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ziVbGe6sU2QS"
   },
   "outputs": [],
   "source": [
    "#### 자유롭게 Model을 만들고 compile 해봅시다 ####\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, input_dim=784, activation=\"relu\"),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVhLJHJ9U2QT"
   },
   "source": [
    "내가 만든 모델을 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GChgw-8sU2QT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209,514\n",
      "Trainable params: 209,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9zWRRHIU2QT"
   },
   "source": [
    "model을 자유롭게 train 해봅시다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6uygJ19gU2QT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2565 - accuracy: 0.9236\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1145 - accuracy: 0.9645\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0845 - accuracy: 0.9736\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0710 - accuracy: 0.9778\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0591 - accuracy: 0.9806\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0517 - accuracy: 0.9827\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0466 - accuracy: 0.9846\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0422 - accuracy: 0.9862\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0364 - accuracy: 0.9875\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0346 - accuracy: 0.9890\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0333 - accuracy: 0.9884\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0304 - accuracy: 0.9899\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0275 - accuracy: 0.9907\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0265 - accuracy: 0.9912\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0262 - accuracy: 0.9911\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0265 - accuracy: 0.9912\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0245 - accuracy: 0.9915\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0212 - accuracy: 0.9929\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0201 - accuracy: 0.9932\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0216 - accuracy: 0.9931\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0195 - accuracy: 0.9933\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0202 - accuracy: 0.9935\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0173 - accuracy: 0.9944\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0184 - accuracy: 0.9940\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0176 - accuracy: 0.9945\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0190 - accuracy: 0.9937\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0172 - accuracy: 0.9944\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0176 - accuracy: 0.9945\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0166 - accuracy: 0.9948\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0175 - accuracy: 0.9948\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0166 - accuracy: 0.9947\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0147 - accuracy: 0.9957\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0160 - accuracy: 0.9951\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0147 - accuracy: 0.9950\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0142 - accuracy: 0.9955\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0138 - accuracy: 0.9956\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0139 - accuracy: 0.9957\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0149 - accuracy: 0.9953\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0143 - accuracy: 0.9956\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0106 - accuracy: 0.9968\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0130 - accuracy: 0.9960\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0136 - accuracy: 0.9959\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0132 - accuracy: 0.9961\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0140 - accuracy: 0.9960\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0111 - accuracy: 0.9962\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0121 - accuracy: 0.9961\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0127 - accuracy: 0.9963\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0144 - accuracy: 0.9956\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0105 - accuracy: 0.9970\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0118 - accuracy: 0.9961\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0118 - accuracy: 0.9961\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0117 - accuracy: 0.9966\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0137 - accuracy: 0.9957\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0117 - accuracy: 0.9965\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0100 - accuracy: 0.9969\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0132 - accuracy: 0.9959\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0122 - accuracy: 0.9965\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0116 - accuracy: 0.9964\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0119 - accuracy: 0.9964\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0109 - accuracy: 0.9968\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0097 - accuracy: 0.9969\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0096 - accuracy: 0.9970\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0108 - accuracy: 0.9966\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0087 - accuracy: 0.9974\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0094 - accuracy: 0.9973\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0107 - accuracy: 0.9970\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0093 - accuracy: 0.9973\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0124 - accuracy: 0.9966\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0076 - accuracy: 0.9974\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0087 - accuracy: 0.9975\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0085 - accuracy: 0.9974\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0091 - accuracy: 0.9975\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0107 - accuracy: 0.9970\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0081 - accuracy: 0.9977\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0104 - accuracy: 0.9971\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0100 - accuracy: 0.9973\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0081 - accuracy: 0.9976\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0094 - accuracy: 0.9973\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0090 - accuracy: 0.9977\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0080 - accuracy: 0.9977\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0090 - accuracy: 0.9972\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0089 - accuracy: 0.9975\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0088 - accuracy: 0.9974\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0080 - accuracy: 0.9974\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0080 - accuracy: 0.9980\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0087 - accuracy: 0.9973\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0090 - accuracy: 0.9977\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0093 - accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b93fb75a00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8A4zKnEU2QT"
   },
   "source": [
    "94%이상의 성능을 가진 모델을 만들면 완성!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9Xz0qGifU2QU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.1301 - accuracy: 0.9839 - 538ms/epoch - 2ms/step\n",
      "\n",
      "Accuracy: 0.9839000105857849\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "print('\\nAccuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "EbcuzK_PU2QU"
   },
   "source": [
    "![](https://www.tensorflow.org/versions/master/images/mnist_tensorboard.png)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DL(MLP)_과제.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
